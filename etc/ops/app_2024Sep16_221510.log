2024-09-16 22:15:10,249 - INFO - Starting configuration setup
2024-09-16 22:15:10,250 - INFO - Environment variables loaded successfully
2024-09-16 22:15:10,250 - INFO - Twitter API client initialized successfully
2024-09-16 22:15:12,882 - INFO - Initializing summarization model: facebook/bart-large-cnn
2024-09-16 22:15:21,067 - INFO - Summarization model initialized successfully
2024-09-16 22:15:21,068 - INFO - Starting tweet scheduling
2024-09-16 22:15:21,068 - INFO - Tweeting process started at 2024-09-16 22:15:21.068068!
2024-09-16 22:15:21,068 - INFO - Loaded posted URLs from /home/runner/work/TechInsightX/TechInsightX/src/../etc/ops/posted_links_2024Sep16.csv
2024-09-16 22:15:21,068 - INFO - Fetching latest tech news from RSS feeds
2024-09-16 22:15:44,606 - INFO - Total entries found: 622
2024-09-16 22:15:44,609 - INFO - Recent AI-related entries found: 21
2024-09-16 22:15:44,609 - INFO - Input content - content='<figure>\n      <img alt="Vector illustration of the ChatGPT logo." src="https://cdn.vox-cdn.com/thumbor/9wFN_XCEf9H6R3yOiF33uwi28DA=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/73590150/STK155_OPEN_AI_CVirginia_B.0.jpg" />\n        <figcaption>Image: The Verge</figcaption>\n    </figure>\n\n  <p id="fWkiDB">OpenAI is turning its Safety and Security Committee into an independent â€œBoard oversight committeeâ€ that has the authority to delay model launches over safety concerns, <a href="https://openai.com/index/update-on-safety-and-security-practices/">according to an OpenAI blog post</a>. The committee made the recommendation to make the independent board after a recent 90-day review of OpenAIâ€™s â€œsafety and security-related processes and safeguards.â€</p>\n<p id="HKAFqD">The committee, which is chaired by <a href="https://www.theverge.com/2024/8/8/24216256/openai-gets-a-new-board-member">Zico Kolter</a> and includes Adam Dâ€™Angelo, <a href="https://www.theverge.com/2024/6/13/24178079/openai-board-paul-nakasone-nsa-safety">Paul Nakasone</a>, and <a href="https://www.theverge.com/2024/3/8/24094885/openai-sam-altman-investigation-board-results">Nicole Seligman</a>, will â€œbe briefed by company leadership on safety evaluations for major model releases, and will, along with the full board, exercise oversight over model launches, including having the authority to delay a release until safety concerns are addressed,â€ OpenAI says....</p>\n  <p>\n    <a href="https://www.theverge.com/2024/9/16/24246617/openai-independent-safety-board-stop-model-releases">Continue reading&hellip;</a>\n  </p>'
2024-09-16 22:15:44,610 - INFO - clean content - clean_content='Image: The Verge OpenAI is turning its Safety and Security Committee into an independent â€œBoard oversight committeeâ€ that has the authority to delay model launches over safety concerns, according to an OpenAI blog post. The committee made the recommendation to make the independent board after a recent 90-day review of OpenAIâ€™s â€œsafety and security-related processes and safeguards.â€ The committee, which is chaired by Zico Kolter and includes Adam Dâ€™Angelo, Paul Nakasone, and Nicole Seligman, will â€œbe briefed by company leadership on safety evaluations for major model releases, and will, along with the full board, exercise oversight over model launches, including having the authority to delay a release until safety concerns are addressed,â€ OpenAI says.... Continue reading&hellip;'
2024-09-16 22:15:44,610 - INFO - Generating summary with BART model
2024-09-16 22:15:50,591 - INFO - Generating summary with BART model
2024-09-16 22:15:54,983 - INFO - full_tweet='OpenAI is turning its Safety and Security Committee into an independent â€œBoard oversight committeeâ€ The..[read moreğŸ‘‡ğŸ¼] #committee #independent https://www.theverge.com/2024/9/16/24246617/openai-independent-safety-board-stop-model-releases'
2024-09-16 22:15:55,087 - ERROR - Failed to post tweet: 429 Too Many Requests
Too Many Requests

2024-09-20 03:14:52,964 - INFO - Starting configuration setup
2024-09-20 03:14:52,964 - INFO - Environment variables loaded successfully
2024-09-20 03:14:52,964 - INFO - Twitter API client initialized successfully
2024-09-20 03:14:54,844 - INFO - Initializing summarization model: facebook/bart-large-cnn
2024-09-20 03:15:03,882 - INFO - Summarization model initialized successfully
2024-09-20 03:15:03,882 - INFO - Starting tweet scheduling
2024-09-20 03:15:03,883 - INFO - Tweeting process started at 2024-09-20 03:15:03.882981!
2024-09-20 03:15:03,883 - INFO - Loaded posted URLs from /home/runner/work/TechInsightX/TechInsightX/src/../etc/ops/posted_links_2024Sep20.csv
2024-09-20 03:15:03,883 - INFO - Fetching latest tech news from RSS feeds
2024-09-20 03:15:24,292 - INFO - Total entries found: 587
2024-09-20 03:15:24,295 - INFO - Recent AI-related entries found: 16
2024-09-20 03:15:24,296 - INFO - Input content - content='<!-- SC_OFF --><div class="md"><p>Hi fellow friends, I have a consultation for this group regarding my career in AI. </p> <p>I have been working as a software engineer (mostly in managerial positions) in the last 9 years, the last 3 as a ML Engineer. I have been doing projects around vision, nlp and recently with LLMs. In this period of time I have mainly worked on creating solutions for specific use cases which base models were not enough. I have been doing data collection, training models, fine tuning and all the MLops required for production applications (optimizing models through distillation, AWS, scaling etc). </p> <p>I have a non technical degree in business administration and law (which I regret ü§£). Ever since I decided during university to switch to be a software engineer I have learned everything by my own from online materials and books. </p> <p>Recently I have been feeling an urge to deepen my knowledge into ML. I have started reading more advanced papers, took a course in linear algebra, calculus and statistics and generally want to advance into more technical topics. </p> <p>I have been thinking of pursuing a masters degree in AI. There are some online programs which I applied for (that allow industry experience instead of a bachelor in CS) and I have some questions that maybe some of the professionals here could help me with regarding the next steps of my career. </p> <ol> <li><p>Do you think masters degree is a must in this field? </p></li> <li><p>I am applying to some good universities and not so well known. For example Maryville University. Do you think in case I don‚Äôt get accepted to the good ones that a degree from a lesser known institution is still better without?</p></li> <li><p>If I want to go on the route of a phd, do I have a chance considering my academic background?</p></li> <li><p>If I want to go on the route of a more research oriented position. What do you think I should do given all this info and what are the next steps I should take. </p></li> </ol> <p>Thank you for taking the time to read it. I would appreciate your answers and any other suggestions you might have üôèüèº</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/slateraligator"> /u/slateraligator </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/1fl0ido/d_advice_on_masters_degree_in_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/1fl0ido/d_advice_on_masters_degree_in_ai/">[comments]</a></span>'
2024-09-20 03:15:24,297 - INFO - clean content - clean_content='Hi fellow friends, I have a consultation for this group regarding my career in AI. I have been working as a software engineer (mostly in managerial positions) in the last 9 years, the last 3 as a ML Engineer. I have been doing projects around vision, nlp and recently with LLMs. In this period of time I have mainly worked on creating solutions for specific use cases which base models were not enough. I have been doing data collection, training models, fine tuning and all the MLops required for production applications (optimizing models through distillation, AWS, scaling etc). I have a non technical degree in business administration and law (which I regret ü§£). Ever since I decided during university to switch to be a software engineer I have learned everything by my own from online materials and books. Recently I have been feeling an urge to deepen my knowledge into ML. I have started reading more advanced papers, took a course in linear algebra, calculus and statistics and generally want to advance into more technical topics. I have been thinking of pursuing a masters degree in AI. There are some online programs which I applied for (that allow industry experience instead of a bachelor in CS) and I have some questions that maybe some of the professionals here could help me with regarding the next steps of my career. Do you think masters degree is a must in this field? I am applying to some good universities and not so well known. For example Maryville University. Do you think in case I don‚Äôt get accepted to the good ones that a degree from a lesser known institution is still better without? If I want to go on the route of a phd, do I have a chance considering my academic background? If I want to go on the route of a more research oriented position. What do you think I should do given all this info and what are the next steps I should take. Thank you for taking the time to read it. I would appreciate your answers and any other suggestions you might have üôèüèº &#32; submitted by &#32; /u/slateraligator [link] &#32; [comments]'
2024-09-20 03:15:24,297 - INFO - Generating summary with BART model
2024-09-20 03:15:33,881 - INFO - Generating summary with BART model
2024-09-20 03:15:42,851 - INFO - full_tweet='I have been working as a software engineer (mostly in managerial positions) in the last 9 years, the last..[read moreüëáüèº] #software #ML https://www.reddit.com/r/MachineLearning/comments/1fl0ido/d_advice_on_masters_degree_in_ai/'
2024-09-20 03:15:43,097 - INFO - Tweet posted successfully: Response(data={'text': 'I have been working as a software engineer (mostly in managerial positions) in the last 9 years, the last..[read moreüëáüèº] #software #ML https://t.co/5RmBJ6UZYa', 'edit_history_tweet_ids': ['1836967445917225197'], 'id': '1836967445917225197'}, includes={}, errors=[], meta={})
2024-09-20 03:15:43,098 - INFO - Sleeping for 9 minutes and 6 seconds.
2024-09-20 03:24:49,098 - INFO - Saved posted URL: https://www.reddit.com/r/MachineLearning/comments/1fl0ido/d_advice_on_masters_degree_in_ai/ at 2024-09-20 03:24:49
2024-09-20 03:24:49,098 - INFO - Input content - content='Amazon debuts new AI features ahead of Prime Day.'
2024-09-20 03:24:49,098 - INFO - clean content - clean_content='Amazon debuts new AI features ahead of Prime Day.'
2024-09-20 03:24:49,098 - INFO - Generating summary with BART model
2024-09-20 03:24:54,100 - INFO - Generating summary with BART model
2024-09-20 03:24:59,074 - INFO - full_tweet='Amazon debuts new AI features ahead of Prime Day. The company is also rolling out a new voice-activated..[read moreüëáüèº] #AI #new https://www.techradar.com/computing/artificial-intelligence/amazons-new-ai-feature-might-be-your-secret-weapon-for-winning-at-prime-day'
2024-09-20 03:24:59,313 - INFO - Tweet posted successfully: Response(data={'text': 'Amazon debuts new AI features ahead of Prime Day. The company is also rolling out a new voice-activated..[read moreüëáüèº] #AI #new https://t.co/FAPhFLGEZl', 'edit_history_tweet_ids': ['1836969778889760866'], 'id': '1836969778889760866'}, includes={}, errors=[], meta={})
2024-09-20 03:24:59,314 - INFO - Sleeping for 4 minutes and 5 seconds.
2024-09-20 03:29:04,314 - INFO - Saved posted URL: https://www.techradar.com/computing/artificial-intelligence/amazons-new-ai-feature-might-be-your-secret-weapon-for-winning-at-prime-day at 2024-09-20 03:29:04
2024-09-20 03:29:04,314 - INFO - Input content - content='<p>California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly contentious SB 1047, which the state&#8217;s legislature sent to his desk for final approval. These bills try to address the most pressing issues in artificial intelligence: everything from futuristic AI systems creating existential risk, deepfake nudes from AI image generators, to Hollywood [&#8230;]</p>\n<p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>'
2024-09-20 03:29:04,314 - INFO - clean content - clean_content='California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly contentious SB 1047, which the state&#8217;s legislature sent to his desk for final approval. These bills try to address the most pressing issues in artificial intelligence: everything from futuristic AI systems creating existential risk, deepfake nudes from AI image generators, to Hollywood [&#8230;] ¬© 2024 TechCrunch. All rights reserved. For personal use only.'
2024-09-20 03:29:04,314 - INFO - Generating summary with BART model
2024-09-20 03:29:08,752 - INFO - Generating summary with BART model
2024-09-20 03:29:13,181 - INFO - full_tweet='California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly..[read moreüëáüèº] #AI #bills https://techcrunch.com/2024/09/19/here-is-whats-illegal-under-californias-8-and-counting-new-ai-laws/'
2024-09-20 03:29:13,374 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836970844456898796'], 'text': 'California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly..[read moreüëáüèº] #AI #bills https://t.co/3QdKgdzEDd', 'id': '1836970844456898796'}, includes={}, errors=[], meta={})
2024-09-20 03:29:13,374 - INFO - Sleeping for 1 minutes and 15 seconds.
2024-09-20 03:30:28,375 - INFO - Saved posted URL: https://techcrunch.com/2024/09/19/here-is-whats-illegal-under-californias-8-and-counting-new-ai-laws/ at 2024-09-20 03:30:28
2024-09-20 03:30:28,375 - INFO - Input content - content='New SocialAI app keeps interactions limited to AI chatbots.'
2024-09-20 03:30:28,375 - INFO - clean content - clean_content='New SocialAI app keeps interactions limited to AI chatbots.'
2024-09-20 03:30:28,375 - INFO - Generating summary with BART model
2024-09-20 03:30:32,735 - INFO - Generating summary with BART model
2024-09-20 03:30:37,096 - INFO - full_tweet='New SocialAI app keeps interactions limited to AI chatbots. The app is designed to help people interact..[read moreüëáüèº] #app #AI https://www.techradar.com/computing/artificial-intelligence/socialai-makes-you-the-most-important-and-only-person-on-social-media'
2024-09-20 03:30:37,288 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836971196417823020'], 'text': 'New SocialAI app keeps interactions limited to AI chatbots. The app is designed to help people interact..[read moreüëáüèº] #app #AI https://t.co/ZuQImvqgG5', 'id': '1836971196417823020'}, includes={}, errors=[], meta={})
2024-09-20 03:30:37,288 - INFO - Sleeping for 5 minutes and 9 seconds.
2024-09-20 03:35:46,289 - INFO - Saved posted URL: https://www.techradar.com/computing/artificial-intelligence/socialai-makes-you-the-most-important-and-only-person-on-social-media at 2024-09-20 03:35:46
2024-09-20 03:35:46,289 - INFO - Input content - content='"The level of partnership and collaboration...is amazing," DHS head says.'
2024-09-20 03:35:46,289 - INFO - clean content - clean_content='"The level of partnership and collaboration...is amazing," DHS head says.'
2024-09-20 03:35:46,289 - INFO - Generating summary with BART model
2024-09-20 03:35:50,388 - INFO - Generating summary with BART model
2024-09-20 03:35:54,476 - INFO - full_tweet='"The level of partnership and collaboration...is amazing," DHS head says. "Thelevel of partnership ... is..[read moreüëáüèº] #partnership #DHS https://www.techradar.com/pro/us-dhs-head-when-it-comes-to-ai-government-needs-to-move-as-fast-as-businesses'
2024-09-20 03:35:54,721 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836972527798866016'], 'text': '"The level of partnership and collaboration...is amazing," DHS head says. "Thelevel of partnership ... is..[read moreüëáüèº] #partnership #DHS https://t.co/TOERYc4qAP', 'id': '1836972527798866016'}, includes={}, errors=[], meta={})
2024-09-20 03:35:54,721 - INFO - Sleeping for 4 minutes and 45 seconds.
2024-09-20 03:40:39,721 - INFO - Saved posted URL: https://www.techradar.com/pro/us-dhs-head-when-it-comes-to-ai-government-needs-to-move-as-fast-as-businesses at 2024-09-20 03:40:39
2024-09-20 03:40:39,721 - INFO - Input content - content='<h4>My first encounters with the o1\xa0model</h4><figure><img alt="An image generated by DALL-E with a prompt the same as the blog title." src="https://cdn-images-1.medium.com/max/1024/1*Bh01W8elWj5paq8T_3a1tQ.jpeg" /><figcaption>An image generated by DALL-E with a prompt precisely the same as the blog\xa0title.</figcaption></figure><h3>My first encounters with the o1\xa0model</h3><p>On the 12th of September at 10:00 a.m., I was in the class ‚Äú<strong>Frontier Topics in Generative AI</strong>,‚Äù a graduate-level course at Arizona State University. A day before this, on the 11th of September, I submitted a team assignment that involved trying to identify flaws and erroneous outputs generated by GPT-4 (essentially trying to prompt GPT-4 to see if it makes mistakes on trivial questions or high-school-level reasoning questions) as part of another graduate-level class ‚Äú<strong>Topics in Natural Language Processing.‚Äù</strong> We identified several trivial mistakes that GPT-4 made, one of them being <em>unable to count the number of r‚Äôs in the word strawberry</em>. Before submitting this assignment, I researched several peer-reviewed papers on the internet that identified where and why GPT -4 made mistakes and how you could rectify them. Most of the documents I came across identified two main domains where GPT-4 erred, and they dealt with <strong>planning and reasoning</strong>.</p><p>This paper¬π (although almost a year old) goes in depth through several cases where GPT-4 fails to answer trivial questions that involve simple counting, simple arithmetic, elementary logic, and even common sense. The paper¬π reasons that these questions require some level of reasoning and that because GPT-4 is utterly incapable of reasoning, it almost always gets these questions wrong. The author also states that reasoning is a (very) computationally hard problem. Although GPT-4 is very compute-intensive, its <strong>compute-intensive nature is not geared towards involving reasoning</strong> in solving the questions that it‚Äôs prompted with. Several other papers echo this notion of GPT-4 being unable to reason or\xa0plan¬≤¬≥.</p><p>Well, let‚Äôs get back to the 12th of September. My class ends at around 10:15 a.m., and I come back straight home from class and open up YouTube on my phone as I dig into my morning brunch. The first recommendation on my YouTube homepage was a video from OpenAI announcing the release of GPT-o1 named ‚Äú<a href="https://youtu.be/3k89FMJhZ00?feature=shared">Building OpenAI o1</a>‚Äù. They announced that this model is a straight-up a <strong>reasoning model </strong>and that it would take more time to reason and answer your questions providing more accurate answers. They state that they have put more compute time into RL (Reinforcement Learning) than previous models to generate coherent <strong><em>chains-of-thoughts‚Å¥</em></strong>. Essentially, they have trained the chain of thought generation process using Reinforcement learning (to generate and hone its own generated chain of thought process). In the o1 models, the engineers were able to ask the model questions as to why it was wrong (whenever it was wrong) in its chain-of-thought process and it could identify the mistakes and correct itself from them. The model could question itself and have to reflect (see ‚ÄúReflection in LLMs‚Äù) on its outputs and correct\xa0itself.</p><p>In another video ‚Äú<a href="https://youtu.be/3BkQI3nIiB8?feature=shared">Reasoning with OpenAI o1</a>‚Äù, <a href="https://www.linkedin.com/in/jerry-tworek-b5b9aa56/">Jerry Tworek</a> demonstrates how previous OpenAI and most other LLMs in the market tend to fail on the following prompt:</p><blockquote>‚ÄúAssume the laws of physics on earth. A small strawberry is put into a normal cup and the cup is placed upside down on a table. Someone then takes the cup and puts it inside the microwave. Where is the strawberry now? Explain your reasoning step by\xa0step.‚Äù</blockquote><p>Legacy GPT-4 answers as\xa0follows:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uavcpaSd8YTpwoLYcj6_YA.png" /><figcaption>Figure 1: GPT-4 getting the strawberry in a cup question\xa0wrong</figcaption></figure><p>The relatively newer GPT-4o also gets it\xa0wrong:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*vMq3ATGYKkUP4Nehl0JBow.png" /><figcaption>Figure 2: GPT-4 o getting the strawberry in a cup question\xa0wrong</figcaption></figure><p>GPT o1 gets the answer\xa0right:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*tdyoYYjdtOW_Es9TT97E7w.png" /><figcaption>Figure 3: GPT o1 getting the answer to the strawberry in a cup question\xa0right</figcaption></figure><p>If you click on the dropdown at the beginning of the model‚Äôs response (see Figure 4), you know that it elicits its thought process (chain-of-thought), and the researchers at OpenAI claim that the o1 model has been trained with reinforcement learning to get this chain of thought better. Also, it‚Äôs interesting to note that <a href="https://www.linkedin.com/in/jason-wei-5a7323b0/">Jason Wei</a> (you can see him sitting third from the right on the bottom row in the video ‚Äú<a href="https://youtu.be/3k89FMJhZ00?feature=shared">Building OpenAI o1</a>‚Äù), the author of the chain-of-thought paper‚Å¥ that he published back at Google, is now an OpenAI employee that is working on the o1 model to integrate the chain-of-thought (that he discovered at Google) process into this\xa0model.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/715/1*6FNw5V_CasKHIEv-ybcaxg.png" /><figcaption>Figure 4: Chain-of-thought elicitation by GPT\xa0o1</figcaption></figure><p>Now, let‚Äôs get back to the counting question that my team found out about as part of my assignment.</p><blockquote>How many r‚Äôs are in the word strawberry?</blockquote><p>Let‚Äôs run this question on\xa0GPT-4o:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TeDTDQ3vgBE_fOqTIOgHwQ.png" /><figcaption>Figure 5: GPT4o getting the number of r‚Äôs in strawberry question\xa0wrong.</figcaption></figure><p>A very simple counting problem that it get‚Äôs\xa0wrong.</p><p>Let‚Äôs run this on the new GPT\xa0o1:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*q7ObqVwDIHUY8hfoNZnHAQ.png" /><figcaption>Figure 6: GPT o1 getting the number of r‚Äôs in strawberry question\xa0right.</figcaption></figure><p>GPT o1 gets the answer right by thinking for a couple of seconds. The researchers at OpenAI say that it goes through its response repeatedly and thinks its way to the right answer. There does seem to be really significant improvements in terms of the model‚Äôs ability to solve a lot of academic exam questions.</p><p>Anyways after I opened up X.com (Formerly Twitter), I came across several people showcasing their attempts at trying to make the o1 model fail. This is a fascinating one I came across (this <a href="https://x.com/creeoer/status/1834588136749388035">tweet</a> by @creeor) where the model fails to answer a trivial question in which the answer lies in the question itself. So I tried the exact same prompt on my account and it gave me the wrong answer (see Figure\xa07).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BB8M867R7Xkcdi1s2Lc-TA.png" /><figcaption>Figure 7: OpenAI o1 is still getting simple riddles wrong when you tweak the riddle. Shows that the models still rely on a lot of the memorization that happened during it‚Äôs training and isn‚Äôt fully using it‚Äôs reasoning capabilities.</figcaption></figure><p>When I ask it what this classic riddle is that it is talking about it tells me about a riddle that it memorized from the internet. It‚Äôs interesting to see how these models can sometimes fall back on memorized content rather than truly reasoning through a problem. Despite the significant advancements and <a href="https://cdn.openai.com/o1-system-card.pdf">benchmark</a> improvements, there are still areas where AI models struggle, especially with tasks that require deeper reasoning or understanding context in a nuanced way. While benchmarks can show progress, real-world applications often reveal the limitations. It‚Äôs through continuous testing, feedback, and real-world use cases that these models can be further\xa0refined.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*UDOjGGL0ugZ7yMu5rpOfQg.png" /><figcaption>Figure 8: o1 blindly answers from a riddle it memorized. It doesn‚Äôt read the question that was given to it and try to answer it as presented.</figcaption></figure><p>There was a <a href="https://medium.com/@aliborji/a-categorical-archive-of-chatgpt-failures-2c888805d3c3">compilation</a> of ChatGPT failures done about a year and a half back. Compilations of model errors are invaluable for understanding and improving AI systems. I‚Äôm sure people will come up with another compilation of errors for the o1 model\xa0soon.</p><p>Although I agree entirely that the chain-of-thought process benefits both AI and human learning, real learning indeed comes from experience and making mistakes.</p><p>I will continue to keep posting my findings on the o1 model on my Medium page. Follow my account to keep posted. And thank you for taking the time to read my Medium\xa0post.</p><h3>References:</h3><p>[1] Arkoudas, Konstantine. ‚ÄúGPT-4 can‚Äôt reason.‚Äù <em>arXiv preprint arXiv:2308.03762</em> (2023).</p><p>[2] Aghzal, Mohamed, Erion Plaku, and Ziyu Yao. ‚ÄúLook Further Ahead: Testing the Limits of GPT-4 in Path Planning.‚Äù <em>arXiv preprint arXiv:2406.12000</em> (2024).</p><p>[3] Kambhampati, Subbarao, et al. ‚ÄúLLMs Can‚Äôt Plan, But Can Help Planning in LLM-Modulo Frameworks.‚Äù <em>arXiv preprint arXiv:2402.01817</em> (2024).</p><p>[4] Wei, Jason, et al. ‚ÄúChain-of-thought prompting elicits reasoning in large language models.‚Äù <em>Advances in neural information processing systems</em> 35 (2022): 24824‚Äì24837.</p><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=99396d641fff" width="1" /><hr /><p><a href="https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff">OpenAI o1: Is This the Enigmatic Force That Will Reshape Every Knowledge Sector We Know?</a> was originally published in <a href="https://towardsdatascience.com">Towards Data Science</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'
2024-09-20 03:40:39,724 - INFO - clean content - clean_content='My first encounters with the o1 modelAn image generated by DALL-E with a prompt precisely the same as the blog title.My first encounters with the o1 modelOn the 12th of September at 10:00 a.m., I was in the class ‚ÄúFrontier Topics in Generative AI,‚Äù a graduate-level course at Arizona State University. A day before this, on the 11th of September, I submitted a team assignment that involved trying to identify flaws and erroneous outputs generated by GPT-4 (essentially trying to prompt GPT-4 to see if it makes mistakes on trivial questions or high-school-level reasoning questions) as part of another graduate-level class ‚ÄúTopics in Natural Language Processing.‚Äù We identified several trivial mistakes that GPT-4 made, one of them being unable to count the number of r‚Äôs in the word strawberry. Before submitting this assignment, I researched several peer-reviewed papers on the internet that identified where and why GPT -4 made mistakes and how you could rectify them. Most of the documents I came across identified two main domains where GPT-4 erred, and they dealt with planning and reasoning.This paper¬π (although almost a year old) goes in depth through several cases where GPT-4 fails to answer trivial questions that involve simple counting, simple arithmetic, elementary logic, and even common sense. The paper¬π reasons that these questions require some level of reasoning and that because GPT-4 is utterly incapable of reasoning, it almost always gets these questions wrong. The author also states that reasoning is a (very) computationally hard problem. Although GPT-4 is very compute-intensive, its compute-intensive nature is not geared towards involving reasoning in solving the questions that it‚Äôs prompted with. Several other papers echo this notion of GPT-4 being unable to reason or plan¬≤¬≥.Well, let‚Äôs get back to the 12th of September. My class ends at around 10:15 a.m., and I come back straight home from class and open up YouTube on my phone as I dig into my morning brunch. The first recommendation on my YouTube homepage was a video from OpenAI announcing the release of GPT-o1 named ‚ÄúBuilding OpenAI o1‚Äù. They announced that this model is a straight-up a reasoning model and that it would take more time to reason and answer your questions providing more accurate answers. They state that they have put more compute time into RL (Reinforcement Learning) than previous models to generate coherent chains-of-thoughts‚Å¥. Essentially, they have trained the chain of thought generation process using Reinforcement learning (to generate and hone its own generated chain of thought process). In the o1 models, the engineers were able to ask the model questions as to why it was wrong (whenever it was wrong) in its chain-of-thought process and it could identify the mistakes and correct itself from them. The model could question itself and have to reflect (see ‚ÄúReflection in LLMs‚Äù) on its outputs and correct itself.In another video ‚ÄúReasoning with OpenAI o1‚Äù, Jerry Tworek demonstrates how previous OpenAI and most other LLMs in the market tend to fail on the following prompt:‚ÄúAssume the laws of physics on earth. A small strawberry is put into a normal cup and the cup is placed upside down on a table. Someone then takes the cup and puts it inside the microwave. Where is the strawberry now? Explain your reasoning step by step.‚ÄùLegacy GPT-4 answers as follows:Figure 1: GPT-4 getting the strawberry in a cup question wrongThe relatively newer GPT-4o also gets it wrong:Figure 2: GPT-4 o getting the strawberry in a cup question wrongGPT o1 gets the answer right:Figure 3: GPT o1 getting the answer to the strawberry in a cup question rightIf you click on the dropdown at the beginning of the model‚Äôs response (see Figure 4), you know that it elicits its thought process (chain-of-thought), and the researchers at OpenAI claim that the o1 model has been trained with reinforcement learning to get this chain of thought better. Also, it‚Äôs interesting to note that Jason Wei (you can see him sitting third from the right on the bottom row in the video ‚ÄúBuilding OpenAI o1‚Äù), the author of the chain-of-thought paper‚Å¥ that he published back at Google, is now an OpenAI employee that is working on the o1 model to integrate the chain-of-thought (that he discovered at Google) process into this model.Figure 4: Chain-of-thought elicitation by GPT o1Now, let‚Äôs get back to the counting question that my team found out about as part of my assignment.How many r‚Äôs are in the word strawberry?Let‚Äôs run this question on GPT-4o:Figure 5: GPT4o getting the number of r‚Äôs in strawberry question wrong.A very simple counting problem that it get‚Äôs wrong.Let‚Äôs run this on the new GPT o1:Figure 6: GPT o1 getting the number of r‚Äôs in strawberry question right.GPT o1 gets the answer right by thinking for a couple of seconds. The researchers at OpenAI say that it goes through its response repeatedly and thinks its way to the right answer. There does seem to be really significant improvements in terms of the model‚Äôs ability to solve a lot of academic exam questions.Anyways after I opened up X.com (Formerly Twitter), I came across several people showcasing their attempts at trying to make the o1 model fail. This is a fascinating one I came across (this tweet by @creeor) where the model fails to answer a trivial question in which the answer lies in the question itself. So I tried the exact same prompt on my account and it gave me the wrong answer (see Figure 7).Figure 7: OpenAI o1 is still getting simple riddles wrong when you tweak the riddle. Shows that the models still rely on a lot of the memorization that happened during it‚Äôs training and isn‚Äôt fully using it‚Äôs reasoning capabilities.When I ask it what this classic riddle is that it is talking about it tells me about a riddle that it memorized from the internet. It‚Äôs interesting to see how these models can sometimes fall back on memorized content rather than truly reasoning through a problem. Despite the significant advancements and benchmark improvements, there are still areas where AI models struggle, especially with tasks that require deeper reasoning or understanding context in a nuanced way. While benchmarks can show progress, real-world applications often reveal the limitations. It‚Äôs through continuous testing, feedback, and real-world use cases that these models can be further refined.Figure 8: o1 blindly answers from a riddle it memorized. It doesn‚Äôt read the question that was given to it and try to answer it as presented.There was a compilation of ChatGPT failures done about a year and a half back. Compilations of model errors are invaluable for understanding and improving AI systems. I‚Äôm sure people will come up with another compilation of errors for the o1 model soon.Although I agree entirely that the chain-of-thought process benefits both AI and human learning, real learning indeed comes from experience and making mistakes.I will continue to keep posting my findings on the o1 model on my Medium page. Follow my account to keep posted. And thank you for taking the time to read my Medium post.References:[1] Arkoudas, Konstantine. ‚ÄúGPT-4 can‚Äôt reason.‚Äù arXiv preprint arXiv:2308.03762 (2023).[2] Aghzal, Mohamed, Erion Plaku, and Ziyu Yao. ‚ÄúLook Further Ahead: Testing the Limits of GPT-4 in Path Planning.‚Äù arXiv preprint arXiv:2406.12000 (2024).[3] Kambhampati, Subbarao, et al. ‚ÄúLLMs Can‚Äôt Plan, But Can Help Planning in LLM-Modulo Frameworks.‚Äù arXiv preprint arXiv:2402.01817 (2024).[4] Wei, Jason, et al. ‚ÄúChain-of-thought prompting elicits reasoning in large language models.‚Äù Advances in neural information processing systems 35 (2022): 24824‚Äì24837.OpenAI o1: Is This the Enigmatic Force That Will Reshape Every Knowledge Sector We Know? was originally published in Towards Data Science on Medium, where people are continuing the conversation by highlighting and responding to this story.'
2024-09-20 03:40:39,724 - INFO - Generating summary with BART model
2024-09-20 03:40:43,871 - INFO - Generating summary with BART model
2024-09-20 03:40:48,050 - INFO - full_tweet='My first encounters with the o1 model. An image generated by DALL-E with a prompt precisely the same as the blog title. #with #encounters https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=rss----7f60cf5620c9---4'
2024-09-20 03:40:48,295 - INFO - Tweet posted successfully: Response(data={'id': '1836973759171064315', 'text': 'My first encounters with the o1 model. An image generated by DALL-E with a prompt precisely the same as the blog title. #with #encounters https://t.co/hW6mMOc8qu', 'edit_history_tweet_ids': ['1836973759171064315']}, includes={}, errors=[], meta={})
2024-09-20 03:40:48,295 - INFO - Sleeping for 6 minutes and 47 seconds.
2024-09-20 03:47:35,296 - INFO - Saved posted URL: https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=rss----7f60cf5620c9---4 at 2024-09-20 03:47:35
2024-09-20 03:47:35,296 - INFO - Input content - content='The digital adviser helps users swiftly navigate the 24-step "Disciplined Entrepreneurship" process.'
2024-09-20 03:47:35,296 - INFO - clean content - clean_content='The digital adviser helps users swiftly navigate the 24-step "Disciplined Entrepreneurship" process.'
2024-09-20 03:47:35,296 - INFO - Generating summary with BART model
2024-09-20 03:47:39,282 - INFO - Generating summary with BART model
2024-09-20 03:47:43,258 - INFO - full_tweet='The digital adviser helps users swiftly navigate the 24-step "Disciplined Entrepreneurship" process. The..[read moreüëáüèº] #digital #adviser https://news.mit.edu/2024/new-ai-jetpack-accelerates-entrepreneurial-process-0919'
2024-09-20 03:47:43,513 - INFO - Tweet posted successfully: Response(data={'id': '1836975500679696493', 'text': 'The digital adviser helps users swiftly navigate the 24-step "Disciplined Entrepreneurship" process. The..[read moreüëáüèº] #digital #adviser https://t.co/J5T7yL8x8l', 'edit_history_tweet_ids': ['1836975500679696493']}, includes={}, errors=[], meta={})
2024-09-20 03:47:43,513 - INFO - Sleeping for 3 minutes and 32 seconds.
2024-09-20 03:51:15,514 - INFO - Saved posted URL: https://news.mit.edu/2024/new-ai-jetpack-accelerates-entrepreneurial-process-0919 at 2024-09-20 03:51:15
2024-09-20 03:51:15,514 - INFO - Input content - content='Product pages are getting AI in every nook and cranny, with new seller tools that create video ads, item descriptions, and brand stories at the push of a button.'
2024-09-20 03:51:15,514 - INFO - clean content - clean_content='Product pages are getting AI in every nook and cranny, with new seller tools that create video ads, item descriptions, and brand stories at the push of a button.'
2024-09-20 03:51:15,514 - INFO - Generating summary with BART model
2024-09-20 03:51:19,704 - INFO - Generating summary with BART model
2024-09-20 03:51:23,917 - INFO - full_tweet='Product pages are getting AI in every nook and cranny. New seller tools create video ads, item..[read moreüëáüèº] #AI #descriptions https://www.pcmag.com/news/shopping-on-amazon-almost-everything-you-see-could-soon-be-ai-generated'
2024-09-20 03:51:24,123 - INFO - Tweet posted successfully: Response(data={'id': '1836976425959838120', 'edit_history_tweet_ids': ['1836976425959838120'], 'text': 'Product pages are getting AI in every nook and cranny. New seller tools create video ads, item..[read moreüëáüèº] #AI #descriptions https://t.co/27WCClLFIr'}, includes={}, errors=[], meta={})
2024-09-20 03:51:24,123 - INFO - Sleeping for 6 minutes and 49 seconds.
2024-09-20 03:58:13,123 - INFO - Saved posted URL: https://www.pcmag.com/news/shopping-on-amazon-almost-everything-you-see-could-soon-be-ai-generated at 2024-09-20 03:58:13
2024-09-20 03:58:13,123 - INFO - Input content - content='By analyzing X-ray crystallography data, the model could help researchers develop new materials for many applications, including batteries and magnets.'
2024-09-20 03:58:13,124 - INFO - clean content - clean_content='By analyzing X-ray crystallography data, the model could help researchers develop new materials for many applications, including batteries and magnets.'
2024-09-20 03:58:13,124 - INFO - Generating summary with BART model
2024-09-20 03:58:17,157 - INFO - Generating summary with BART model
2024-09-20 03:58:21,182 - INFO - full_tweet='Model could help develop new materials for many applications, including batteries and magnets. By..[read moreüëáüèº] #data #develop https://news.mit.edu/2024/ai-model-can-reveal-crystalline-materials-structures-0919'
2024-09-20 03:58:21,411 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836978176280645791'], 'text': 'Model could help develop new materials for many applications, including batteries and magnets. By..[read moreüëáüèº] #data #develop https://t.co/khrEtgroOz', 'id': '1836978176280645791'}, includes={}, errors=[], meta={})
2024-09-20 03:58:21,411 - INFO - Sleeping for 8 minutes and 33 seconds.
2024-09-20 04:06:54,411 - INFO - Saved posted URL: https://news.mit.edu/2024/ai-model-can-reveal-crystalline-materials-structures-0919 at 2024-09-20 04:06:54
2024-09-20 04:06:54,411 - INFO - Input content - content='Carolyn Geason-Beissel/MIT SMR &#124; Getty Images Can AI be creative? While this question often leads to philosophical debates about the meaning of creativity, one fact is clear: Many creative professionals are already using an increasing array of AI tools.1 Art directors, copywriters, and others are harnessing generative AI‚Äôs capabilities to generate a large stream of [&#8230;]'
2024-09-20 04:06:54,412 - INFO - clean content - clean_content='Carolyn Geason-Beissel/MIT SMR &#124; Getty Images Can AI be creative? While this question often leads to philosophical debates about the meaning of creativity, one fact is clear: Many creative professionals are already using an increasing array of AI tools.1 Art directors, copywriters, and others are harnessing generative AI‚Äôs capabilities to generate a large stream of [&#8230;]'
2024-09-20 04:06:54,412 - INFO - Generating summary with BART model
2024-09-20 04:06:58,444 - INFO - Generating summary with BART model
2024-09-20 04:07:02,465 - INFO - full_tweet='Many creative professionals are already using an increasing array of AI tools. Art directors,..[read moreüëáüèº] #AI #professionals https://sloanreview.mit.edu/article/how-genai-changes-creative-work/'
2024-09-20 04:07:02,693 - INFO - Tweet posted successfully: Response(data={'text': 'Many creative professionals are already using an increasing array of AI tools. Art directors,..[read moreüëáüèº] #AI #professionals https://t.co/yh5SfRSNVg', 'id': '1836980362708439385', 'edit_history_tweet_ids': ['1836980362708439385']}, includes={}, errors=[], meta={})
2024-09-20 04:07:02,693 - INFO - Sleeping for 9 minutes and 33 seconds.
2024-09-20 04:16:35,693 - INFO - Saved posted URL: https://sloanreview.mit.edu/article/how-genai-changes-creative-work/ at 2024-09-20 04:16:35
2024-09-20 04:16:35,693 - INFO - Input content - content='<img height="417" src="https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2024%2F09%2FUntitled-design-8.jpg&amp;signature=776b91a00afeff4f06fb09cf9bfe1d35" width="796" /><br />This year, Air Canada lost a lawsuit against a customer who was misled by an AI chatbot into purchasing full-price plane tickets, being assured they would later be refunded under the company‚Äôs bereavement policy. The airline tried to claim the bot was ‚Äúresponsible for its own actions.‚Äù This line of argumentation was rejected by the court and the company not only had to pay compensation, it also received public criticism for attempting to distance itself from the situation. It‚Äôs clear companies are liable for AI models, even when they make mistakes beyond our control. The rapidly advancing world of AI,&#8230;<br /><br /><a href="https://thenextweb.com/news/ai-hallucinate-why-human-tech-users-pitfall?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed">This story continues</a> at The Next Web'
2024-09-20 04:16:35,694 - INFO - clean content - clean_content='This year, Air Canada lost a lawsuit against a customer who was misled by an AI chatbot into purchasing full-price plane tickets, being assured they would later be refunded under the company‚Äôs bereavement policy. The airline tried to claim the bot was ‚Äúresponsible for its own actions.‚Äù This line of argumentation was rejected by the court and the company not only had to pay compensation, it also received public criticism for attempting to distance itself from the situation. It‚Äôs clear companies are liable for AI models, even when they make mistakes beyond our control. The rapidly advancing world of AI,&#8230;This story continues at The Next Web'
2024-09-20 04:16:35,694 - INFO - Generating summary with BART model
2024-09-20 04:16:42,128 - INFO - Generating summary with BART model
2024-09-20 04:16:48,568 - INFO - full_tweet='Air Canada lost a lawsuit against a customer who was misled by an AI chatbot into purchasing full-price..[read moreüëáüèº] #AI #by https://thenextweb.com/news/ai-hallucinate-why-human-tech-users-pitfall'
2024-09-20 04:16:48,798 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836982820998369424'], 'id': '1836982820998369424', 'text': 'Air Canada lost a lawsuit against a customer who was misled by an AI chatbot into purchasing full-price..[read moreüëáüèº] #AI #by https://t.co/ZITtMQTs0V'}, includes={}, errors=[], meta={})
2024-09-20 04:16:48,799 - INFO - Sleeping for 1 minutes and 37 seconds.
2024-09-20 04:18:25,799 - INFO - Saved posted URL: https://thenextweb.com/news/ai-hallucinate-why-human-tech-users-pitfall at 2024-09-20 04:18:25
2024-09-20 04:18:25,799 - INFO - Input content - content='A group that includes sex workers, sex tech businesses, and sex educators has demanded a seat at the table to shape AI regulations that they say could lead to discrimination against them.'
2024-09-20 04:18:25,799 - INFO - clean content - clean_content='A group that includes sex workers, sex tech businesses, and sex educators has demanded a seat at the table to shape AI regulations that they say could lead to discrimination against them.'
2024-09-20 04:18:25,799 - INFO - Generating summary with BART model
2024-09-20 04:18:29,788 - INFO - Generating summary with BART model
2024-09-20 04:18:33,776 - INFO - full_tweet='Sex workers, sex tech businesses, and sex educators have demanded a seat at the table to shape AI..[read moreüëáüèº] #AI #tech https://www.wired.com/story/content-creators-in-the-adult-industry-want-a-say-in-ai-rules/'
2024-09-20 04:18:33,961 - INFO - Tweet posted successfully: Response(data={'id': '1836983262096544202', 'text': 'Sex workers, sex tech businesses, and sex educators have demanded a seat at the table to shape AI..[read moreüëáüèº] #AI #tech https://t.co/DHa8bBvy3e', 'edit_history_tweet_ids': ['1836983262096544202']}, includes={}, errors=[], meta={})
2024-09-20 04:18:33,961 - INFO - Sleeping for 9 minutes and 33 seconds.
2024-09-20 04:28:06,961 - INFO - Saved posted URL: https://www.wired.com/story/content-creators-in-the-adult-industry-want-a-say-in-ai-rules/ at 2024-09-20 04:28:06
2024-09-20 04:28:06,961 - INFO - Input content - content='<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://towardsdatascience.com/the-basics-behind-ai-models-for-self-driving-cars-42fd0e1f58b4?source=rss----7f60cf5620c9---4"><img src="https://cdn-images-1.medium.com/max/2600/1*FHNP7kNIBWmXmFSqhB5eQA.jpeg" width="4032" /></a></p><p class="medium-feed-snippet">Learn to build a neutral network that can drive using PyTorch in Python</p><p class="medium-feed-link"><a href="https://towardsdatascience.com/the-basics-behind-ai-models-for-self-driving-cars-42fd0e1f58b4?source=rss----7f60cf5620c9---4">Continue reading on Towards Data Science ¬ª</a></p></div>'
2024-09-20 04:28:06,962 - INFO - clean content - clean_content='Learn to build a neutral network that can drive using PyTorch in PythonContinue reading on Towards Data Science ¬ª'
2024-09-20 04:28:06,962 - INFO - Generating summary with BART model
2024-09-20 04:28:12,872 - INFO - Generating summary with BART model
2024-09-20 04:28:18,836 - INFO - full_tweet='Learn to build a neutral network that can drive using PyTorch in Python. Learn to build an open source..[read moreüëáüèº] #network #data https://towardsdatascience.com/the-basics-behind-ai-models-for-self-driving-cars-42fd0e1f58b4?source=rss----7f60cf5620c9---4'
2024-09-20 04:28:19,153 - INFO - Tweet posted successfully: Response(data={'id': '1836985716502643107', 'text': 'Learn to build a neutral network that can drive using PyTorch in Python. Learn to build an open source..[read moreüëáüèº] #network #data https://t.co/MvXc5H0q19', 'edit_history_tweet_ids': ['1836985716502643107']}, includes={}, errors=[], meta={})
2024-09-20 04:28:19,153 - INFO - Sleeping for 8 minutes and 14 seconds.
2024-09-20 04:36:33,154 - INFO - Saved posted URL: https://towardsdatascience.com/the-basics-behind-ai-models-for-self-driving-cars-42fd0e1f58b4?source=rss----7f60cf5620c9---4 at 2024-09-20 04:36:33
2024-09-20 04:36:33,154 - INFO - Input content - content='<!-- SC_OFF --><div class="md"><p>I tried a Kaggle competition <a href="https://www.kaggle.com/competitions/playground-series-s3e19">https://www.kaggle.com/competitions/playground-series-s3e19</a> on Google\'s Data Science Agent tool - basically I just dumped the description as prompt and uploaded the datasets there, and it generated this Jupyter notebook: <a href="https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4">https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4</a></p> <p>I also tried it on ChatGPT but unfortunately I don\'t have Plus so the task was terminated in the middle (no model was trained). Anyone with Plus tried kaggle tasks on ChatGPT? Wondering how long will we see a bot win the competition, I imagine RL would play a huge role here.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/caterpillarous"> /u/caterpillarous </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/">[comments]</a></span>'
2024-09-20 04:36:33,154 - INFO - clean content - clean_content="I tried a Kaggle competition on Google's Data Science Agent tool - basically I just dumped the description as prompt and uploaded the datasets there, and it generated this Jupyter notebook: I also tried it on ChatGPT but unfortunately I don't have Plus so the task was terminated in the middle (no model was trained). Anyone with Plus tried kaggle tasks on ChatGPT? Wondering how long will we see a bot win the competition, I imagine RL would play a huge role here. &#32; submitted by &#32; /u/caterpillarous [link] &#32; [comments]"
2024-09-20 04:36:33,154 - INFO - Generating summary with BART model
2024-09-20 04:36:41,635 - INFO - Generating summary with BART model
2024-09-20 04:36:50,155 - INFO - full_tweet="I tried a Kaggle competition on Google's Data Science Agent tool - basically I just dumped the..[read moreüëáüèº] #Data #I https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/"
2024-09-20 04:36:50,410 - INFO - Tweet posted successfully: Response(data={'id': '1836987860857278753', 'edit_history_tweet_ids': ['1836987860857278753'], 'text': "I tried a Kaggle competition on Google's Data Science Agent tool - basically I just dumped the..[read moreüëáüèº] #Data #I https://t.co/9NRvYh82jW"}, includes={}, errors=[], meta={})
2024-09-20 04:36:50,410 - INFO - Sleeping for 2 minutes and 45 seconds.
2024-09-20 04:39:35,410 - INFO - Saved posted URL: https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/ at 2024-09-20 04:39:35
2024-09-20 04:39:35,410 - INFO - Input content - content='A UN report proposes that the organization take a much more active role in the monitoring and oversight of AI.'
2024-09-20 04:39:35,410 - INFO - clean content - clean_content='A UN report proposes that the organization take a much more active role in the monitoring and oversight of AI.'
2024-09-20 04:39:35,410 - INFO - Generating summary with BART model
2024-09-20 04:39:40,321 - INFO - Generating summary with BART model
2024-09-20 04:39:45,247 - INFO - full_tweet='A UN report proposes that the organization take a much more active role in the monitoring and oversight..[read moreüëáüèº] #AI #report https://www.wired.com/story/united-nations-artificial-intelligence-report/'
2024-09-20 04:39:45,417 - INFO - Tweet posted successfully: Response(data={'text': 'A UN report proposes that the organization take a much more active role in the monitoring and oversight..[read moreüëáüèº] #AI #report https://t.co/YgNkTRgLII', 'edit_history_tweet_ids': ['1836988594977968321'], 'id': '1836988594977968321'}, includes={}, errors=[], meta={})
2024-09-20 04:39:45,418 - INFO - Sleeping for 8 minutes and 59 seconds.
2024-09-20 04:48:44,418 - INFO - Saved posted URL: https://www.wired.com/story/united-nations-artificial-intelligence-report/ at 2024-09-20 04:48:44
2024-09-20 04:48:44,418 - INFO - Input content - content='Researchers find large language models make inconsistent decisions about whether to call the police when analyzing surveillance videos.'
2024-09-20 04:48:44,418 - INFO - clean content - clean_content='Researchers find large language models make inconsistent decisions about whether to call the police when analyzing surveillance videos.'
2024-09-20 04:48:44,418 - INFO - Generating summary with BART model
2024-09-20 04:48:48,425 - INFO - Generating summary with BART model
2024-09-20 04:48:52,401 - INFO - full_tweet='Researchers find large language models make inconsistent decisions about whether to call the police when..[read moreüëáüèº] #inconsistent #Researchers https://news.mit.edu/2024/study-ai-inconsistent-outcomes-home-surveillance-0919'
2024-09-20 04:48:52,622 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1836990890138874069'], 'id': '1836990890138874069', 'text': 'Researchers find large language models make inconsistent decisions about whether to call the police when..[read moreüëáüèº] #inconsistent #Researchers https://t.co/yIbdI38o9E'}, includes={}, errors=[], meta={})
2024-09-20 04:48:52,622 - INFO - Sleeping for 9 minutes and 13 seconds.
2024-09-20 04:58:05,623 - INFO - Saved posted URL: https://news.mit.edu/2024/study-ai-inconsistent-outcomes-home-surveillance-0919 at 2024-09-20 04:58:05

2024-10-20 17:09:53,390 - INFO - Starting configuration setup
2024-10-20 17:09:53,390 - INFO - Environment variables loaded successfully
2024-10-20 17:09:53,390 - INFO - Twitter API client initialized successfully
2024-10-20 17:09:55,252 - INFO - Initializing summarization model: facebook/bart-large-cnn
2024-10-20 17:10:06,017 - INFO - Summarization model initialized successfully
2024-10-20 17:10:06,017 - INFO - Starting tweet scheduling
2024-10-20 17:10:06,017 - INFO - Tweeting process started at 2024-10-20 17:10:06.017747!
2024-10-20 17:10:06,018 - INFO - Loaded posted URLs from /home/runner/work/TechInsightX/TechInsightX/src/../etc/ops/posted_links_2024Oct20.csv
2024-10-20 17:10:06,018 - INFO - Fetching latest tech news from RSS feeds
2024-10-20 17:10:30,226 - INFO - Total entries found: 615
2024-10-20 17:10:30,229 - INFO - Recent AI-related entries found: 16
2024-10-20 17:10:30,229 - INFO - Input content - content='<p>AI companies claim to have robust safety checks in place that ensure that models don&#8217;t say or do weird, illegal, or unsafe stuff. But what if the models were capable of evading those checks and, for some reason, trying to sabotage or mislead users? Turns out they can do this, according to Anthropic researchers. Just [&#8230;]</p>\n<p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>'
2024-10-20 17:10:30,229 - INFO - clean content - clean_content='AI companies claim to have robust safety checks in place that ensure that models don‚Äôt say or do weird, illegal, or unsafe stuff. But what if the models were capable of evading those checks and, for some reason, trying to sabotage or mislead users? Turns out they can do this, according to Anthropic researchers. Just [‚Ä¶] ¬© 2024 TechCrunch. All rights reserved. For personal use only.'
2024-10-20 17:10:30,229 - INFO - Generating summary with BART model
2024-10-20 17:10:37,191 - INFO - Generating summary with BART model
2024-10-20 17:10:43,548 - INFO - full_tweet='AI companies claim to have robust safety checks in place. But what if the models were capable of evading..[read moreüëáüèº] #AI #checks https://techcrunch.com/2024/10/20/can-ai-sandbag-safety-checks-to-sabotage-users-yes-but-not-very-well-for-now/'
2024-10-20 17:10:43,974 - INFO - Tweet posted successfully: Response(data={'edit_history_tweet_ids': ['1848049220013437374'], 'id': '1848049220013437374', 'text': 'AI companies claim to have robust safety checks in place. But what if the models were capable of evading..[read moreüëáüèº] #AI #checks https://t.co/aXNYsXNzx1'}, includes={}, errors=[], meta={})
2024-10-20 17:10:43,974 - INFO - Saved posted URL: https://techcrunch.com/2024/10/20/can-ai-sandbag-safety-checks-to-sabotage-users-yes-but-not-very-well-for-now/ at 2024-10-20 17:10:43
2024-10-20 17:10:43,974 - INFO - Tweet link saved successfully.
2024-10-20 17:10:43,975 - INFO - Sleeping for 5 minutes and 40 seconds.
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://techcrunch.com/2024/10/20/gustos-head-of-technology-says-hiring-an-army-of-specialists-is-the-wrong-approach-to-ai/
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://techcrunch.com/2024/10/20/investments-in-generative-ai-startups-topped-3-9b-in-q3-2024/
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.reddit.com/r/MachineLearning/comments/1g7yzh8/d_last_week_in_medical_ai_top_llm_research/
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.cnet.com/how-to/ai-told-me-what-to-eat-for-a-week-heres-how-it-went/#ftag=CAD590a51e
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.cnet.com/tech/services-and-software/features/is-ai-the-answer-to-your-money-problems-were-starting-to-find-out/#ftag=CAD590a51e
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://towardsdatascience.com/why-explainability-matters-in-ai-840144df418e?source=rss----7f60cf5620c9---4
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.techradar.com/computing/artificial-intelligence/ai-marketing-is-a-con-especially-when-it-comes-to-cpus
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.reddit.com/r/MachineLearning/comments/1g7mjgs/endorsement_for_a_ai_paper_in_arvix_r/
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.techradar.com/pro/another-big-win-for-amd-as-lenovo-adds-epyc-9005-and-instinct-mi325x-to-its-thinksystem-server-platform-boosting-ai-capabilities
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://techcrunch.com/2024/10/19/former-openai-cto-mira-murati-is-reportedly-fundraising-for-a-new-ai-startup/
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.pcmag.com/news/major-publisher-penguin-random-house-blocks-ai-training-on-its-books
2024-10-20 17:16:23,975 - INFO - This link is already posted: https://www.reddit.com/r/MachineLearning/comments/1g7ghwx/news_aaai_2025_workshop_on_ai_for_music/
2024-10-20 17:16:23,976 - INFO - This link is already posted: https://techcrunch.com/2024/10/19/four-takeaways-from-pony-ais-ipo-filing/
2024-10-20 17:16:23,976 - INFO - This link is already posted: https://techcrunch.com/2024/10/19/penguin-random-house-is-adding-an-ai-warning-to-its-books-copyright-pages/
2024-10-20 17:16:23,976 - INFO - This link is already posted: https://www.reddit.com/r/MachineLearning/comments/1g7f0qj/discussion_sophon_ai_accelerator_accuracy_problem/
